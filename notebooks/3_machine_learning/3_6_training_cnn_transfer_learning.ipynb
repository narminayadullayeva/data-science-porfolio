{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Convolutional Neural Network\n",
    "\n",
    "In this notebook, we will create a CNN model using PyTorch and then train it on the CIFAR10 dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Installations\n",
    "**NOTE**: Everytime you start the GPU, run this before your code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (7.7.2)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from ipywidgets) (8.4.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jupyterlab-widgets<3,>=1.0.0 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from ipywidgets) (1.0.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from ipywidgets) (5.8.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from ipywidgets) (6.7.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from ipywidgets) (3.6.1)\n",
      "Requirement already satisfied: appnope in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.2)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.3)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.4.9)\n",
      "Requirement already satisfied: nest-asyncio in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.5)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.30)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (65.6.3)\n",
      "Requirement already satisfied: pickleshare in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: backcall in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: stack-data in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.4.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (2.13.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.4.12)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: entrypoints in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: pyzmq>=23.0 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (24.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: argon2-cffi in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.15.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: prometheus-client in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.14.1)\n",
      "Requirement already satisfied: jinja2 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.2)\n",
      "Requirement already satisfied: nbformat in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.4.0)\n",
      "Requirement already satisfied: nbconvert>=5 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.5.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: pure-eval in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: executing in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.10.0)\n",
      "Requirement already satisfied: asttokens in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.0.8)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from jupyter-core>=4.9.2->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.6.0)\n",
      "Requirement already satisfied: tinycss2 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.6.6)\n",
      "Requirement already satisfied: packaging in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.3)\n",
      "Requirement already satisfied: lxml in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.9.1)\n",
      "Requirement already satisfied: defusedxml in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.11.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.1.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: bleach in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.0.1)\n",
      "Requirement already satisfied: fastjsonschema in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.16.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from python-dateutil>=2.8.2->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.15.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.3.2.post1)\n",
      "Requirement already satisfied: webencodings in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from packaging->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: pycparser in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/narmina/.pyenv/versions/3.8.10/envs/env-3.8.10/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.8.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.8 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets\n",
    "#!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Device mps\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 0, Phase train\n",
      "Images [2000/50000 (4%)] Loss: 1.10 Accuracy: 873/2000 (43.65%) Time: Sat Feb  4 10:51:36 2023\n",
      "Images [4000/50000 (8%)] Loss: 1.16 Accuracy: 2129/4000 (53.23%) Time: Sat Feb  4 10:51:54 2023\n",
      "Images [6000/50000 (12%)] Loss: 1.24 Accuracy: 3453/6000 (57.55%) Time: Sat Feb  4 10:52:12 2023\n",
      "Images [8000/50000 (16%)] Loss: 0.96 Accuracy: 4861/8000 (60.76%) Time: Sat Feb  4 10:52:31 2023\n",
      "Images [10000/50000 (20%)] Loss: 0.60 Accuracy: 6288/10000 (62.88%) Time: Sat Feb  4 10:52:50 2023\n",
      "Epoch 0, Phase valid\n",
      "Images [2000/10000 (20%)] Loss: 0.49 Accuracy: 1443/2000 (72.15%) Time: Sat Feb  4 10:53:01 2023\n",
      "Epoch 1, Phase train\n",
      "Images [2000/50000 (4%)] Loss: 0.78 Accuracy: 1363/2000 (68.15%) Time: Sat Feb  4 10:53:19 2023\n",
      "Images [4000/50000 (8%)] Loss: 0.85 Accuracy: 2759/4000 (68.97%) Time: Sat Feb  4 10:53:37 2023\n",
      "Images [6000/50000 (12%)] Loss: 0.30 Accuracy: 4167/6000 (69.45%) Time: Sat Feb  4 10:53:54 2023\n",
      "Images [8000/50000 (16%)] Loss: 1.02 Accuracy: 5587/8000 (69.84%) Time: Sat Feb  4 10:54:12 2023\n",
      "Images [10000/50000 (20%)] Loss: 0.62 Accuracy: 6987/10000 (69.87%) Time: Sat Feb  4 10:54:31 2023\n",
      "Epoch 1, Phase valid\n",
      "Images [2000/10000 (20%)] Loss: 0.71 Accuracy: 1547/2000 (77.35%) Time: Sat Feb  4 10:54:41 2023\n",
      "Testing Model on Whole Testing Dataset\n",
      "Testing Accuracy: 77.77, Testing Loss: 0.6574979763254524\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time # for measuring time for testing, remove for students\n",
    "\n",
    "def test(model, test_loader, criterion, device):\n",
    "    print(\"Testing Model on Whole Testing Dataset\")\n",
    "    model.eval()\n",
    "    running_loss=0\n",
    "    running_corrects=0\n",
    "    \n",
    "    for inputs, labels in test_loader:\n",
    "        inputs=inputs.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs=model(inputs)\n",
    "        loss=criterion(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data).item()\n",
    "\n",
    "    total_loss = running_loss / len(test_loader.dataset)\n",
    "    total_acc = running_corrects/ len(test_loader.dataset)\n",
    "    print(f\"Testing Accuracy: {100*total_acc}, Testing Loss: {total_loss}\")\n",
    "    \n",
    "def train(model, train_loader, validation_loader, criterion, optimizer, device):\n",
    "    epochs=2\n",
    "    best_loss=1e6\n",
    "    image_dataset={'train':train_loader, 'valid':validation_loader}\n",
    "    loss_counter=0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for phase in ['train', 'valid']:\n",
    "            print(f\"Epoch {epoch}, Phase {phase}\")\n",
    "            if phase=='train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            running_samples=0\n",
    "\n",
    "            for step, (inputs, labels) in enumerate(image_dataset[phase]):\n",
    "                inputs=inputs.to(device)\n",
    "                labels=labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase=='train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data).item()\n",
    "                running_samples+=len(inputs)\n",
    "                if running_samples % 2000  == 0:\n",
    "                    accuracy = running_corrects/running_samples\n",
    "                    print(\"Images [{}/{} ({:.0f}%)] Loss: {:.2f} Accuracy: {}/{} ({:.2f}%) Time: {}\".format(\n",
    "                            running_samples,\n",
    "                            len(image_dataset[phase].dataset),\n",
    "                            100.0 * (running_samples / len(image_dataset[phase].dataset)),\n",
    "                            loss.item(),\n",
    "                            running_corrects,\n",
    "                            running_samples,\n",
    "                            100.0*accuracy,\n",
    "                            time.asctime() # for measuring time for testing, remove for students and in the formatting\n",
    "                        )\n",
    "                    )\n",
    "                \n",
    "                #NOTE: Comment lines below to train and test on whole dataset\n",
    "                if running_samples>(0.2*len(image_dataset[phase].dataset)):\n",
    "                    break\n",
    "\n",
    "            epoch_loss = running_loss / running_samples\n",
    "            epoch_acc = running_corrects / running_samples\n",
    "            \n",
    "            if phase=='valid':\n",
    "                if epoch_loss<best_loss:\n",
    "                    best_loss=epoch_loss\n",
    "                else:\n",
    "                    loss_counter+=1\n",
    "\n",
    "        if loss_counter==1:\n",
    "            break\n",
    "    return model\n",
    "\n",
    "def create_model():\n",
    "    model = models.resnet18(pretrained=True)\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False   \n",
    "\n",
    "    num_features=model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "                   nn.Linear(num_features, 10))\n",
    "    return model\n",
    "\n",
    "batch_size=10\n",
    "\n",
    "if torch.backends.mps.is_available(): # for Apple Silicon users\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available(): \n",
    "    torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Running on Device {device}\")\n",
    "\n",
    "training_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "testing_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "        download=True, transform=training_transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "        shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "        download=True, transform=testing_transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "        shuffle=False)\n",
    "\n",
    "model=create_model()\n",
    "model=model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "train(model, trainloader, testloader, criterion, optimizer, device)\n",
    "\n",
    "test(model, testloader, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try It Out!\n",
    "- Play around with the number of layers and filters in your model. How does the accuracy change? How long does it take to train the model?\n",
    "- Try to train your model with some other types of convolutional layers like depthwise separable convolutions\n",
    "- Can you create the same network in TensorFlow as well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning CNN\n",
    "\n",
    "Here we will be fine tuning Resnet 18 on CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Device mps\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 0, Phase train\n",
      "Images [2000/50000 (4%)] Loss: 1.27 Accuracy: 857/2000 (42.85%)\n",
      "Images [4000/50000 (8%)] Loss: 0.68 Accuracy: 2110/4000 (52.75%)\n",
      "Images [6000/50000 (12%)] Loss: 0.89 Accuracy: 3499/6000 (58.32%)\n",
      "Images [8000/50000 (16%)] Loss: 0.79 Accuracy: 4869/8000 (60.86%)\n",
      "Images [10000/50000 (20%)] Loss: 1.30 Accuracy: 6251/10000 (62.51%)\n",
      "Epoch 0, Phase valid\n",
      "Images [2000/10000 (20%)] Loss: 0.54 Accuracy: 1463/2000 (73.15%)\n",
      "Epoch 1, Phase train\n",
      "Images [2000/50000 (4%)] Loss: 0.48 Accuracy: 1391/2000 (69.55%)\n",
      "Images [4000/50000 (8%)] Loss: 0.69 Accuracy: 2818/4000 (70.45%)\n",
      "Images [6000/50000 (12%)] Loss: 1.31 Accuracy: 4245/6000 (70.75%)\n",
      "Images [8000/50000 (16%)] Loss: 0.81 Accuracy: 5658/8000 (70.73%)\n",
      "Images [10000/50000 (20%)] Loss: 0.53 Accuracy: 7104/10000 (71.04%)\n",
      "Epoch 1, Phase valid\n",
      "Images [2000/10000 (20%)] Loss: 0.64 Accuracy: 1564/2000 (78.20%)\n",
      "Testing Model on Whole Testing Dataset\n",
      "Testing Accuracy: 78.13, Testing Loss: 0.6469403550103306\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time # for measuring time for testing, remove for students\n",
    "\n",
    "def test(model, test_loader, criterion, device):\n",
    "    print(\"Testing Model on Whole Testing Dataset\")\n",
    "    model.eval()\n",
    "    running_loss=0\n",
    "    running_corrects=0\n",
    "    \n",
    "    for inputs, labels in test_loader:\n",
    "        inputs=inputs.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs=model(inputs)\n",
    "        loss=criterion(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data).item()\n",
    "\n",
    "    total_loss = running_loss / len(test_loader.dataset)\n",
    "    total_acc = running_corrects/ len(test_loader.dataset)\n",
    "    print(f\"Testing Accuracy: {100*total_acc}, Testing Loss: {total_loss}\")\n",
    "    \n",
    "def train(model, train_loader, validation_loader, criterion, optimizer, device):\n",
    "    epochs=2\n",
    "    best_loss=1e6\n",
    "    image_dataset={'train':train_loader, 'valid':validation_loader}\n",
    "    loss_counter=0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for phase in ['train', 'valid']:\n",
    "            print(f\"Epoch {epoch}, Phase {phase}\")\n",
    "            if phase=='train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            running_samples=0\n",
    "\n",
    "            for step, (inputs, labels) in enumerate(image_dataset[phase]):\n",
    "                inputs=inputs.to(device)\n",
    "                labels=labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase=='train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data).item()\n",
    "                running_samples+=len(inputs)\n",
    "                if running_samples % 2000  == 0:\n",
    "                    accuracy = running_corrects/running_samples\n",
    "                    print(\"Images [{}/{} ({:.0f}%)] Loss: {:.2f} Accuracy: {}/{} ({:.2f}%)\".format(\n",
    "                            running_samples,\n",
    "                            len(image_dataset[phase].dataset),\n",
    "                            100.0 * (running_samples / len(image_dataset[phase].dataset)),\n",
    "                            loss.item(),\n",
    "                            running_corrects,\n",
    "                            running_samples,\n",
    "                            100.0*accuracy,\n",
    "                        )\n",
    "                    )\n",
    "                \n",
    "                #NOTE: Comment lines below to train and test on whole dataset\n",
    "                if running_samples>(0.2*len(image_dataset[phase].dataset)):\n",
    "                    break\n",
    "\n",
    "            epoch_loss = running_loss / running_samples\n",
    "            epoch_acc = running_corrects / running_samples\n",
    "            \n",
    "            if phase=='valid':\n",
    "                if epoch_loss<best_loss:\n",
    "                    best_loss=epoch_loss\n",
    "                else:\n",
    "                    loss_counter+=1\n",
    "\n",
    "        if loss_counter==1:\n",
    "            break\n",
    "    return model\n",
    "\n",
    "def create_model():\n",
    "    model = models.resnet18(pretrained=True)\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False   \n",
    "\n",
    "    num_features=model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "                   nn.Linear(num_features, 10))\n",
    "    return model\n",
    "\n",
    "batch_size=10\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(f\"Running on Device {device}\")\n",
    "\n",
    "training_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "testing_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "        download=True, transform=training_transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "        shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "        download=True, transform=testing_transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "        shuffle=False)\n",
    "\n",
    "model=create_model()\n",
    "model=model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "train(model, trainloader, testloader, criterion, optimizer, device)\n",
    "\n",
    "test(model, testloader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-3.8.10",
   "language": "python",
   "name": "env-3.8.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
